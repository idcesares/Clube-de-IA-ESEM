{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificação com Árvores de Decisão no Scikit-Learn\n",
    "- Este notebook faz parte da atividades teóricas do clube de Inteligência Artificial da Escola Sesc de Ensino Médio;\n",
    "- Nesta atividade iremos aprender mais sobre algoritmos de Classificação utilizando árvores de Decisão em uma biblioteca muito utilizada para Machine Learning, a Scikit-Learn.\n",
    "\n",
    "## Scikit-Learn\n",
    "- A scikit-learn (originalmente scikits.learn) é uma biblioteca de aprendizado de máquina de código aberto para a linguagem de programação Python. Ela inclui vários algoritmos de classificação, regressão e agrupamento incluindo máquinas de vetores de suporte, florestas aleatórias, gradient boosting, k-means e DBSCAN, e é projetada para interagir com as bibliotecas Python numéricas e científicas NumPy e SciPy.\n",
    "\n",
    "https://scikit-learn.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparando os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Importando as bibliotecas principais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NumPy** é um pacote para a linguagem Python que suporta arrays e matrizes multidimensionais, possuindo uma larga coleção de funções matemáticas para trabalhar com estas estruturas. *Wikipédia*\n",
    "\n",
    "**Pandas** é uma biblioteca de software criada para a linguagem Python para manipulação e análise de dados. Em particular, oferece estruturas e operações para manipular tabelas numéricas e séries temporais. É software livre sob a licensa licença BSD. *Wikipédia*\n",
    "\n",
    "**Matplotlib** é uma biblioteca de software para criação de gráficos e visualizações de dados em geral, feita para a da linguagem de programação Python e sua extensão de matemática NumPy. Originalmente criada pelo biólogo e neurocientista americano John D. *Wikipédia*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Importando  e visualizando o Dataset\n",
    "**Dataset** é uma coleção de dados (conjunto de dados) normalmente tabulados. Por cada elemento se indicam várias características. Cada coluna representa uma variável particular. Cada linha corresponde a um determinado membro do conjunto de dados em questão. Cada valor é conhecido como um dado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sobre o Dataset deste projeto\n",
    "\n",
    "**Diagnóstico de COVID-19 e seu espectro clínico**: https://www.kaggle.com/einsteindata4u/covid19\n",
    "\n",
    "Este conjunto de dados contém dados anônimos de pacientes atendidos no Hospital Israelita Albert Einstein, em São Paulo, Brasil, e que tiveram amostras coletadas para a realização do SARS-CoV-2 RT-PCR e exames laboratoriais adicionais durante uma visita ao hospital.\n",
    "\n",
    "Todos os dados foram tornados anônimos seguindo as melhores práticas e recomendações internacionais. Todos os dados clínicos foram padronizados para ter uma média de zero e um desvio padrão da unidade.\n",
    "\n",
    "**Objetivo:** Com base nos resultados dos testes laboratoriais comumente coletados para um caso suspeito de COVID-19 durante uma visita ao pronto-socorro, o modelo deverá prever a classificação do resultado do teste para SARS-Cov-2 como positivo ou negativo.\n",
    "\n",
    "**Link para o arquivo .csv do Dataset:** https://raw.githubusercontent.com/diogocortiz/Crash-Course-IA/master/ArvoreDecis%C3%A3o/dataset_einstein.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lendo o arquivo que contém os nossos dados e criando um Dataframe com o Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/diogocortiz/Crash-Course-IA/master/ArvoreDecis%C3%A3o/dataset_einstein.csv', sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mostrando as 5 primeiras linhas do Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mostrando as 5 últimas linhas do Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exibindo informações importantes do Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().round(2) # Resume e descreve algumas operações gerais do Dataset. Round(2) arredonda para 2 casas decimais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Tamanho do Dataframe: {df.shape[0]} linhas e {df.shape[1]} colunas') # Descreve o tamanho do dataframe em uma tupla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info() # Descreve informaçoes de tamanho e de tipo das características"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removendo os valores em branco (NaN)\n",
    "Removemos esses valores para evitar ruídos e distorções em nosso modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Dataset com valores em branco: {df.shape[0]}')\n",
    "print(f'Dataset sem valores em branco: {df.dropna().shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### O nosso dataset está balanceado ou desbalanecado?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Total de registros negativos: ', df[df['SARS-Cov-2 exam result'] =='negative'].shape[0])\n",
    "print ('Total de registros positivos: ', df[df['SARS-Cov-2 exam result'] =='positive'].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Selecionando as características principais para o estudo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Qual coluna utilizaremos para realizar nosso experimento?**\n",
    "Quais serão variáveis independentes?\n",
    "Qual será a variável dependente?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecionando as etiquetas (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['SARS-Cov-2 exam result'].values \n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecionando as características (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Hemoglobin', 'Leukocytes', 'Basophils','Proteina C reativa mg/dL']].values\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Criando os datasets de treino e de teste\n",
    "Usando Sklearn para escalar os dados.\n",
    "#### Importando o train_test_split da biblioteca scikit-learn\n",
    "A função train_test_split nos ajuda a dividir o dataset em treino e teste com base nos parâmetros definidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilizando a função train_test_split e inserindo os dados nas variáveis indicadas\n",
    "O test_size representa a proporção do dataset que será incluída na divisão de teste. Os valores pode ir de 0.0 a 1.0.\n",
    "\n",
    "O random_state garante que as divisões geradas sejam reproduzíveis. O Scikit-learn usa permutações aleatórias para gerar as divisões. O estado aleatório que você fornece é usado como uma semente (random seed) para o gerador de números aleatórios. Isso garante que os números aleatórios sejam gerados na mesma ordem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Escolher um modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://scikit-learn.org/stable/_static/ml_map.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Árvores de Decisão\n",
    "Árvores de decisão (DTs) são um método de aprendizado supervisionado não paramétrico usado para classificação e regressão. O objetivo é criar um modelo que preveja o valor de uma variável de destino, aprendendo regras de decisão simples inferidas dos recursos de dados.\n",
    "\n",
    "<img src=\"https://scikit-learn.org/stable/_images/sphx_glr_plot_iris_dtc_0021.png\"/>\n",
    "\n",
    "Fontes: \n",
    "- https://scikit-learn.org/stable/modules/tree.htmls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importando o algoritmo DecisionTreeClassifier de classificação da biblioteca scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_text\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ajustar os dados ao modelo e fazer a classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Instanciar a classe DecisionTreeClassifier()\n",
    "\n",
    "<img src=\"http://jcsites.juniata.edu/faculty/rhodes/ida/images/weatherdectree.GIF\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = DecisionTreeClassifier(criterion='entropy', max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Utilizando o método .fit()\n",
    "O método .fit() do objeto modelo criado da classe DecisionTreeClassifier() treinará o nosso modelo e possibilitará a classificação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Exibindo as principais características e imprimindo a árvore de decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "print (modelo.feature_importances_)\n",
    "nome_features = ['Hemoglobin', 'Leukocytes', 'Basophils','Proteina C reativa mg/dL']\n",
    "nome_classes = modelo.classes_\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "tree.plot_tree(modelo,\n",
    "               feature_names=nome_features,\n",
    "               class_names=nome_classes,\n",
    "               filled=True,\n",
    "               max_depth=4,\n",
    "               fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observando a estrutura em texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = export_text(modelo, feature_names=nome_features)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Fazendo as predições no dataset de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = modelo.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Avaliando o modelo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quais foram as características de maior importância no modelo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = modelo.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "plt.title(\"Feature ranking\", fontsize = 20)\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "    color=\"b\", \n",
    "    align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.ylabel(\"importance\", fontsize = 18)\n",
    "plt.xlabel(\"index of the feature\", fontsize = 18)\n",
    "plt.show()\n",
    "\n",
    "#Indice das features\n",
    "# 0 - 'Hemoglobin', \n",
    "# 1 - 'Leukocytes'\n",
    "# 2 - 'Basophils',\n",
    "# 3 - 'Proteina C reativa mg/dL']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qual a acurácia da nossa árvore?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "print(\"ACURÁCIA DA ÁRVORE: \", accuracy_score(y_test, y_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
